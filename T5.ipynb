{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a2fd8c-7f40-4030-9f90-57c99236195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>director dirk shafer and co-writer greg hinton...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a charming , quirky and leisurely paced scotti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the price was good ,  and came quickly though ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i was looking forward to this game for a coupl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arguably the year 's silliest and most incoher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>an imaginative comedy\\/thriller .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>a savvy exploration of paranoia and insecurity...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>on the other hand for power grating you ve got...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>like dickens with his passages , mcgrath craft...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>those who would follow haneke on his creepy ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id                                               TEXT  LABEL\n",
       "0          0  director dirk shafer and co-writer greg hinton...      0\n",
       "1          1  a charming , quirky and leisurely paced scotti...      1\n",
       "2          2  the price was good ,  and came quickly though ...      1\n",
       "3          3  i was looking forward to this game for a coupl...      0\n",
       "4          4  arguably the year 's silliest and most incoher...      0\n",
       "...      ...                                                ...    ...\n",
       "1995    1995                  an imaginative comedy\\/thriller .      1\n",
       "1996    1996  a savvy exploration of paranoia and insecurity...      1\n",
       "1997    1997  on the other hand for power grating you ve got...      1\n",
       "1998    1998  like dickens with his passages , mcgrath craft...      1\n",
       "1999    1999  those who would follow haneke on his creepy ex...      1\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv('train_2022.csv')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f99116d-b2f5-4a6c-97f3-22621d434dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>good to know if you can t find these elsewhere .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>love it !  the grill plates come out and pop i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i m convinced this was a poorly executed refur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i would never have complained about that if it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the photo shows the same whole ,  large candie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>10995</td>\n",
       "      <td>i didn t quite get it the first time .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>10996</td>\n",
       "      <td>i ve tried installing with and without the oem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>10997</td>\n",
       "      <td>i was parked at a truck stop in the cincinnati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>10998</td>\n",
       "      <td>i recently bought this case after seeing some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>10999</td>\n",
       "      <td>the keyboard types only % of the time and the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id                                               TEXT\n",
       "0           0   good to know if you can t find these elsewhere .\n",
       "1           1  love it !  the grill plates come out and pop i...\n",
       "2           2  i m convinced this was a poorly executed refur...\n",
       "3           3  i would never have complained about that if it...\n",
       "4           4  the photo shows the same whole ,  large candie...\n",
       "...       ...                                                ...\n",
       "10995   10995             i didn t quite get it the first time .\n",
       "10996   10996  i ve tried installing with and without the oem...\n",
       "10997   10997  i was parked at a truck stop in the cincinnati...\n",
       "10998   10998  i recently bought this case after seeing some ...\n",
       "10999   10999  the keyboard types only % of the time and the ...\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv('test_no_answer_2022.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460aabd6-8250-4f59-836b-a9e8537e3c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72920e-bc66-4ff1-b46a-6a1cddede43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e502b402-a20e-4d19-bb60-673ae433130d",
   "metadata": {},
   "source": [
    "# T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33fed1-d253-406b-93b1-db502cbd9fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.0679283142089844\n",
      "Epoch 0, Loss: 2.128352403640747\n",
      "Epoch 0, Loss: 2.1275112628936768\n",
      "Epoch 0, Loss: 1.7556647062301636\n",
      "Epoch 0, Loss: 1.7121444940567017\n",
      "Epoch 0, Loss: 1.5263192653656006\n",
      "Epoch 0, Loss: 1.6478596925735474\n",
      "Epoch 0, Loss: 1.6046369075775146\n",
      "Epoch 0, Loss: 1.4518781900405884\n",
      "Epoch 0, Loss: 1.420722246170044\n",
      "Epoch 0, Loss: 1.2442291975021362\n",
      "Epoch 0, Loss: 1.2705384492874146\n",
      "Epoch 0, Loss: 0.9988387227058411\n",
      "Epoch 0, Loss: 1.0272718667984009\n",
      "Epoch 0, Loss: 0.9811387658119202\n",
      "Epoch 0, Loss: 0.9191348552703857\n",
      "Epoch 0, Loss: 0.7155396342277527\n",
      "Epoch 0, Loss: 0.7217323780059814\n",
      "Epoch 0, Loss: 0.6201804876327515\n",
      "Epoch 0, Loss: 0.5397351980209351\n",
      "Epoch 0, Loss: 0.432305246591568\n",
      "Epoch 0, Loss: 0.3552534282207489\n",
      "Epoch 0, Loss: 0.32101693749427795\n",
      "Epoch 0, Loss: 0.2773313820362091\n",
      "Epoch 0, Loss: 0.2618369460105896\n",
      "Epoch 0, Loss: 0.21358676254749298\n",
      "Epoch 0, Loss: 0.18035222589969635\n",
      "Epoch 0, Loss: 0.1817421019077301\n",
      "Epoch 0, Loss: 0.1652391254901886\n",
      "Epoch 0, Loss: 0.15602125227451324\n",
      "Epoch 0, Loss: 0.14150461554527283\n",
      "Epoch 0, Loss: 0.14285926520824432\n",
      "Epoch 0, Loss: 0.12005360424518585\n",
      "Epoch 0, Loss: 0.12898485362529755\n",
      "Epoch 0, Loss: 0.12069452553987503\n",
      "Epoch 0, Loss: 0.11609593778848648\n",
      "Epoch 0, Loss: 0.10436266660690308\n",
      "Epoch 0, Loss: 0.10546843707561493\n",
      "Epoch 0, Loss: 0.1147942766547203\n",
      "Epoch 0, Loss: 0.09495310485363007\n",
      "Epoch 0, Loss: 0.10092449188232422\n",
      "Epoch 0, Loss: 0.10394211113452911\n",
      "Epoch 0, Loss: 0.09532592445611954\n",
      "Epoch 0, Loss: 0.10299567133188248\n",
      "Epoch 0, Loss: 0.08938390016555786\n",
      "Epoch 0, Loss: 0.10082721710205078\n",
      "Epoch 0, Loss: 0.08907061070203781\n",
      "Epoch 0, Loss: 0.09991467744112015\n",
      "Epoch 0, Loss: 0.09398072212934494\n",
      "Epoch 0, Loss: 0.09929242730140686\n",
      "Epoch 0, Loss: 0.08912447839975357\n",
      "Epoch 0, Loss: 0.09352900832891464\n",
      "Epoch 0, Loss: 0.07948564738035202\n",
      "Epoch 0, Loss: 0.08488523215055466\n",
      "Epoch 0, Loss: 0.09674487262964249\n",
      "Epoch 0, Loss: 0.08291739225387573\n",
      "Epoch 0, Loss: 0.07266935706138611\n",
      "Epoch 0, Loss: 0.08494361490011215\n",
      "Epoch 0, Loss: 0.07750970125198364\n",
      "Epoch 0, Loss: 0.07467314600944519\n",
      "Epoch 0, Loss: 0.07284826040267944\n",
      "Epoch 0, Loss: 0.07772378623485565\n",
      "Epoch 0, Loss: 0.0847337543964386\n",
      "Epoch 0, Loss: 0.07572773098945618\n",
      "Epoch 0, Loss: 0.06880739331245422\n",
      "Epoch 0, Loss: 0.07172535359859467\n",
      "Epoch 0, Loss: 0.07896582782268524\n",
      "Epoch 0, Loss: 0.07634985446929932\n",
      "Epoch 0, Loss: 0.07082650065422058\n",
      "Epoch 0, Loss: 0.06887392699718475\n",
      "Epoch 0, Loss: 0.07534929364919662\n",
      "Epoch 0, Loss: 0.06854656338691711\n",
      "Epoch 0, Loss: 0.06954875588417053\n",
      "Epoch 0, Loss: 0.06327013671398163\n",
      "Epoch 0, Loss: 0.0707695484161377\n",
      "Epoch 0, Loss: 0.06687997281551361\n",
      "Epoch 0, Loss: 0.07085860520601273\n",
      "Epoch 0, Loss: 0.06896144896745682\n",
      "Epoch 0, Loss: 0.07192511111497879\n",
      "Epoch 0, Loss: 0.07014099508523941\n",
      "Epoch 0, Loss: 0.070079006254673\n",
      "Epoch 0, Loss: 0.0714833214879036\n",
      "Epoch 0, Loss: 0.058401454240083694\n",
      "Epoch 0, Loss: 0.06544665992259979\n",
      "Epoch 0, Loss: 0.06854059547185898\n",
      "Epoch 0, Loss: 0.07005132734775543\n",
      "Epoch 0, Loss: 0.06508065015077591\n",
      "Epoch 0, Loss: 0.06531384587287903\n",
      "Epoch 0, Loss: 0.06385532021522522\n",
      "Epoch 0, Loss: 0.06615082919597626\n",
      "Epoch 0, Loss: 0.06576314568519592\n",
      "Epoch 0, Loss: 0.06498672068119049\n",
      "Epoch 0, Loss: 0.05907810479402542\n",
      "Epoch 0, Loss: 0.06639142334461212\n",
      "Epoch 0, Loss: 0.06222402676939964\n",
      "Epoch 0, Loss: 0.06884600967168808\n",
      "Epoch 0, Loss: 0.05827707052230835\n",
      "Epoch 0, Loss: 0.05548781156539917\n",
      "Epoch 0, Loss: 0.06209276244044304\n",
      "Epoch 0, Loss: 0.06392203271389008\n",
      "Epoch 0, Loss: 0.06547194719314575\n",
      "Epoch 0, Loss: 0.06207221373915672\n",
      "Epoch 0, Loss: 0.06240040436387062\n",
      "Epoch 0, Loss: 0.053872957825660706\n",
      "Epoch 0, Loss: 0.05638301372528076\n",
      "Epoch 0, Loss: 0.06309553980827332\n",
      "Epoch 0, Loss: 0.05536718666553497\n",
      "Epoch 0, Loss: 0.058489881455898285\n",
      "Epoch 0, Loss: 0.0614086352288723\n",
      "Epoch 0, Loss: 0.06255170702934265\n",
      "Epoch 0, Loss: 0.05905689299106598\n",
      "Epoch 0, Loss: 0.067186638712883\n",
      "Epoch 0, Loss: 0.06124915927648544\n",
      "Epoch 0, Loss: 0.058042675256729126\n",
      "Epoch 0, Loss: 0.05917754024267197\n",
      "Epoch 0, Loss: 0.051491495221853256\n",
      "Epoch 0, Loss: 0.061667680740356445\n",
      "Epoch 0, Loss: 0.05741081386804581\n",
      "Epoch 0, Loss: 0.05577043816447258\n",
      "Epoch 0, Loss: 0.05488244444131851\n",
      "Epoch 0, Loss: 0.06030254438519478\n",
      "Epoch 0, Loss: 0.05932493880391121\n",
      "Epoch 0, Loss: 0.055676721036434174\n",
      "Epoch 0, Loss: 0.05284646898508072\n",
      "Epoch 0, Loss: 0.05263879895210266\n",
      "Epoch 0, Loss: 0.05462172254920006\n",
      "Epoch 0, Loss: 0.0604870468378067\n",
      "Epoch 0, Loss: 0.05885130167007446\n",
      "Epoch 0, Loss: 0.059288665652275085\n",
      "Epoch 0, Loss: 0.05177883431315422\n",
      "Epoch 0, Loss: 0.058592867106199265\n",
      "Epoch 0, Loss: 0.04844698682427406\n",
      "Epoch 0, Loss: 0.05069998279213905\n",
      "Epoch 0, Loss: 0.04772002622485161\n",
      "Epoch 0, Loss: 0.05148492380976677\n",
      "Epoch 0, Loss: 0.058108266443014145\n",
      "Epoch 0, Loss: 0.05356593802571297\n",
      "Epoch 0, Loss: 0.05089350789785385\n",
      "Epoch 0, Loss: 0.051190394908189774\n",
      "Epoch 0, Loss: 0.049698133021593094\n",
      "Epoch 0, Loss: 0.046057820320129395\n",
      "Epoch 0, Loss: 0.04894442856311798\n",
      "Epoch 0, Loss: 0.054280273616313934\n",
      "Epoch 0, Loss: 0.05393737927079201\n",
      "Epoch 0, Loss: 0.05268291383981705\n",
      "Epoch 0, Loss: 0.04343922436237335\n",
      "Epoch 0, Loss: 0.04826052114367485\n",
      "Epoch 0, Loss: 0.04788598045706749\n",
      "Epoch 0, Loss: 0.05132712423801422\n",
      "Epoch 0, Loss: 0.04394477605819702\n",
      "Epoch 0, Loss: 0.04370316118001938\n",
      "Epoch 0, Loss: 0.04940588399767876\n",
      "Epoch 0, Loss: 0.050048910081386566\n",
      "Epoch 0, Loss: 0.048638373613357544\n",
      "Epoch 0, Loss: 0.048289455473423004\n",
      "Epoch 0, Loss: 0.04873637855052948\n",
      "Epoch 0, Loss: 0.049897465854883194\n",
      "Epoch 0, Loss: 0.055406808853149414\n",
      "Epoch 0, Loss: 0.049593642354011536\n",
      "Epoch 0, Loss: 0.04962073266506195\n",
      "Epoch 0, Loss: 0.046902772039175034\n",
      "Epoch 0, Loss: 0.045499492436647415\n",
      "Epoch 0, Loss: 0.05614833906292915\n",
      "Epoch 0, Loss: 0.04513441026210785\n",
      "Epoch 0, Loss: 0.04934462159872055\n",
      "Epoch 0, Loss: 0.040694210678339005\n",
      "Epoch 0, Loss: 0.0408305898308754\n",
      "Epoch 0, Loss: 0.046848997473716736\n",
      "Epoch 0, Loss: 0.0431353859603405\n",
      "Epoch 0, Loss: 0.04381775110960007\n",
      "Epoch 0, Loss: 0.044870082288980484\n",
      "Epoch 0, Loss: 0.045593131333589554\n",
      "Epoch 0, Loss: 0.04055109992623329\n",
      "Epoch 0, Loss: 0.039288479834795\n",
      "Epoch 0, Loss: 0.04006357118487358\n",
      "Epoch 0, Loss: 0.04041410610079765\n",
      "Epoch 0, Loss: 0.040416158735752106\n",
      "Epoch 0, Loss: 0.04153744503855705\n",
      "Epoch 0, Loss: 0.04043944925069809\n",
      "Epoch 0, Loss: 0.04079592972993851\n",
      "Epoch 0, Loss: 0.04153874143958092\n",
      "Epoch 0, Loss: 0.03668326884508133\n",
      "Epoch 0, Loss: 0.03928618133068085\n",
      "Epoch 0, Loss: 0.03800192475318909\n",
      "Epoch 0, Loss: 0.03533225506544113\n",
      "Epoch 0, Loss: 0.039459966123104095\n",
      "Epoch 0, Loss: 0.03790568560361862\n",
      "Epoch 0, Loss: 0.0374363474547863\n",
      "Epoch 0, Loss: 0.03464865684509277\n",
      "Epoch 0, Loss: 0.03779710456728935\n",
      "Epoch 0, Loss: 0.034664954990148544\n",
      "Epoch 0, Loss: 0.041934072971343994\n",
      "Epoch 0, Loss: 0.0369025357067585\n",
      "Epoch 0, Loss: 0.03497753664851189\n",
      "Epoch 0, Loss: 0.03396255522966385\n",
      "Epoch 0, Loss: 0.03660544008016586\n",
      "Epoch 0, Loss: 0.03223247453570366\n",
      "Epoch 0, Loss: 0.03238195553421974\n",
      "Epoch 0, Loss: 0.03505031019449234\n",
      "Epoch 0, Loss: 0.030209926888346672\n",
      "Epoch 0, Loss: 0.028093775734305382\n",
      "Epoch 0, Loss: 0.031590573489665985\n",
      "Epoch 0, Loss: 0.034090831875801086\n",
      "Epoch 0, Loss: 0.0365210622549057\n",
      "Epoch 0, Loss: 0.02736676298081875\n",
      "Epoch 0, Loss: 0.03421030193567276\n",
      "Epoch 0, Loss: 0.03726768493652344\n",
      "Epoch 0, Loss: 0.02493654191493988\n",
      "Epoch 0, Loss: 0.03242875635623932\n",
      "Epoch 0, Loss: 0.026050614193081856\n",
      "Epoch 0, Loss: 0.02633177489042282\n",
      "Epoch 0, Loss: 0.029553305357694626\n",
      "Epoch 0, Loss: 0.03102348931133747\n",
      "Epoch 0, Loss: 0.02708076313138008\n",
      "Epoch 0, Loss: 0.028542768210172653\n",
      "Epoch 0, Loss: 0.02718452177941799\n",
      "Epoch 0, Loss: 0.024886805564165115\n",
      "Epoch 0, Loss: 0.0245833657681942\n",
      "Epoch 0, Loss: 0.029692672193050385\n",
      "Epoch 0, Loss: 0.023379409685730934\n",
      "Epoch 0, Loss: 0.027691323310136795\n",
      "Epoch 0, Loss: 0.02534346468746662\n",
      "Epoch 0, Loss: 0.020092500373721123\n",
      "Epoch 0, Loss: 0.028702937066555023\n",
      "Epoch 0, Loss: 0.022027045488357544\n",
      "Epoch 1, Loss: 0.02623857371509075\n",
      "Epoch 1, Loss: 0.022815443575382233\n",
      "Epoch 1, Loss: 0.022009151056408882\n",
      "Epoch 1, Loss: 0.019553961232304573\n",
      "Epoch 1, Loss: 0.02217238023877144\n",
      "Epoch 1, Loss: 0.022682975977659225\n",
      "Epoch 1, Loss: 0.017546026036143303\n",
      "Epoch 1, Loss: 0.020467383787035942\n",
      "Epoch 1, Loss: 0.020361077040433884\n",
      "Epoch 1, Loss: 0.019831458106637\n",
      "Epoch 1, Loss: 0.023729946464300156\n",
      "Epoch 1, Loss: 0.024704335257411003\n",
      "Epoch 1, Loss: 0.01837141066789627\n",
      "Epoch 1, Loss: 0.01778724417090416\n",
      "Epoch 1, Loss: 0.015263820998370647\n",
      "Epoch 1, Loss: 0.01378217525780201\n",
      "Epoch 1, Loss: 0.020807459950447083\n",
      "Epoch 1, Loss: 0.014490668661892414\n",
      "Epoch 1, Loss: 0.014196092262864113\n",
      "Epoch 1, Loss: 0.01712946407496929\n",
      "Epoch 1, Loss: 0.01792759634554386\n",
      "Epoch 1, Loss: 0.014167129062116146\n",
      "Epoch 1, Loss: 0.013939062133431435\n",
      "Epoch 1, Loss: 0.016197919845581055\n",
      "Epoch 1, Loss: 0.012846101075410843\n",
      "Epoch 1, Loss: 0.012991207651793957\n",
      "Epoch 1, Loss: 0.017450353130698204\n",
      "Epoch 1, Loss: 0.018143845722079277\n",
      "Epoch 1, Loss: 0.011127838864922523\n",
      "Epoch 1, Loss: 0.01505739614367485\n",
      "Epoch 1, Loss: 0.010935479775071144\n",
      "Epoch 1, Loss: 0.014560392126441002\n",
      "Epoch 1, Loss: 0.010889998637139797\n",
      "Epoch 1, Loss: 0.011113326996564865\n",
      "Epoch 1, Loss: 0.008129999972879887\n",
      "Epoch 1, Loss: 0.010937201790511608\n",
      "Epoch 1, Loss: 0.011489077471196651\n",
      "Epoch 1, Loss: 0.012743777595460415\n",
      "Epoch 1, Loss: 0.011640875600278378\n",
      "Epoch 1, Loss: 0.009674361906945705\n",
      "Epoch 1, Loss: 0.01164353359490633\n",
      "Epoch 1, Loss: 0.009654223918914795\n",
      "Epoch 1, Loss: 0.007681368384510279\n",
      "Epoch 1, Loss: 0.011140099726617336\n",
      "Epoch 1, Loss: 0.012164773419499397\n",
      "Epoch 1, Loss: 0.010044393129646778\n",
      "Epoch 1, Loss: 0.007583432365208864\n",
      "Epoch 1, Loss: 0.006677783094346523\n",
      "Epoch 1, Loss: 0.008362668566405773\n",
      "Epoch 1, Loss: 0.005843235179781914\n",
      "Epoch 1, Loss: 0.0070951832458376884\n",
      "Epoch 1, Loss: 0.010381514206528664\n",
      "Epoch 1, Loss: 0.007870501838624477\n",
      "Epoch 1, Loss: 0.013601923361420631\n",
      "Epoch 1, Loss: 0.006900149863213301\n",
      "Epoch 1, Loss: 0.005851332098245621\n",
      "Epoch 1, Loss: 0.007093655876815319\n",
      "Epoch 1, Loss: 0.006257102824747562\n",
      "Epoch 1, Loss: 0.006891304161399603\n",
      "Epoch 1, Loss: 0.007224120199680328\n",
      "Epoch 1, Loss: 0.007309677544981241\n",
      "Epoch 1, Loss: 0.00546775059774518\n",
      "Epoch 1, Loss: 0.006130211986601353\n",
      "Epoch 1, Loss: 0.0041978247463703156\n",
      "Epoch 1, Loss: 0.006263474468141794\n",
      "Epoch 1, Loss: 0.005633780732750893\n",
      "Epoch 1, Loss: 0.004132736474275589\n",
      "Epoch 1, Loss: 0.0033205216750502586\n",
      "Epoch 1, Loss: 0.006722948979586363\n",
      "Epoch 1, Loss: 0.0028406439814716578\n",
      "Epoch 1, Loss: 0.004517578054219484\n",
      "Epoch 1, Loss: 0.004233913496136665\n",
      "Epoch 1, Loss: 0.0046233064495027065\n",
      "Epoch 1, Loss: 0.003702988848090172\n",
      "Epoch 1, Loss: 0.0055680046789348125\n",
      "Epoch 1, Loss: 0.004193136002868414\n",
      "Epoch 1, Loss: 0.005422983318567276\n",
      "Epoch 1, Loss: 0.004420408979058266\n",
      "Epoch 1, Loss: 0.004196263384073973\n",
      "Epoch 1, Loss: 0.0028632464818656445\n",
      "Epoch 1, Loss: 0.0024990816600620747\n",
      "Epoch 1, Loss: 0.0026046368293464184\n",
      "Epoch 1, Loss: 0.004557599313557148\n",
      "Epoch 1, Loss: 0.002665472449734807\n",
      "Epoch 1, Loss: 0.0023861690424382687\n",
      "Epoch 1, Loss: 0.0036213581915944815\n",
      "Epoch 1, Loss: 0.0024024664890021086\n",
      "Epoch 1, Loss: 0.003673971863463521\n",
      "Epoch 1, Loss: 0.005211080424487591\n",
      "Epoch 1, Loss: 0.005400857888162136\n",
      "Epoch 1, Loss: 0.005966696888208389\n",
      "Epoch 1, Loss: 0.003452366217970848\n",
      "Epoch 1, Loss: 0.0038813077844679356\n",
      "Epoch 1, Loss: 0.005074250511825085\n",
      "Epoch 1, Loss: 0.002458482049405575\n",
      "Epoch 1, Loss: 0.0037570022977888584\n",
      "Epoch 1, Loss: 0.002678487915545702\n",
      "Epoch 1, Loss: 0.006710574496537447\n",
      "Epoch 1, Loss: 0.003619195893406868\n",
      "Epoch 1, Loss: 0.0028721471317112446\n",
      "Epoch 1, Loss: 0.0025149581488221884\n",
      "Epoch 1, Loss: 0.003049128223210573\n",
      "Epoch 1, Loss: 0.0038438187912106514\n",
      "Epoch 1, Loss: 0.0025749187916517258\n",
      "Epoch 1, Loss: 0.0029372877907007933\n",
      "Epoch 1, Loss: 0.005398531444370747\n",
      "Epoch 1, Loss: 0.0038782439660280943\n",
      "Epoch 1, Loss: 0.002944523235782981\n",
      "Epoch 1, Loss: 0.0036212897393852472\n",
      "Epoch 1, Loss: 0.004294965416193008\n",
      "Epoch 1, Loss: 0.003911562263965607\n",
      "Epoch 1, Loss: 0.0041592619381845\n",
      "Epoch 1, Loss: 0.004925218876451254\n",
      "Epoch 1, Loss: 0.002104543149471283\n",
      "Epoch 1, Loss: 0.004160816315561533\n",
      "Epoch 1, Loss: 0.003315341891720891\n",
      "Epoch 1, Loss: 0.0033668475225567818\n",
      "Epoch 1, Loss: 0.00924216490238905\n",
      "Epoch 1, Loss: 0.0027419503312557936\n",
      "Epoch 1, Loss: 0.0020141166169196367\n",
      "Epoch 1, Loss: 0.0024140586610883474\n",
      "Epoch 1, Loss: 0.0020603127777576447\n",
      "Epoch 1, Loss: 0.002895734738558531\n",
      "Epoch 1, Loss: 0.0020275257993489504\n",
      "Epoch 1, Loss: 0.003997692838311195\n",
      "Epoch 1, Loss: 0.004781052935868502\n",
      "Epoch 1, Loss: 0.0035211285576224327\n",
      "Epoch 1, Loss: 0.0030034338124096394\n",
      "Epoch 1, Loss: 0.0019621343817561865\n",
      "Epoch 1, Loss: 0.002091755624860525\n",
      "Epoch 1, Loss: 0.0017745394725352526\n",
      "Epoch 1, Loss: 0.004453582223504782\n",
      "Epoch 1, Loss: 0.0024267863482236862\n",
      "Epoch 1, Loss: 0.002032860415056348\n",
      "Epoch 1, Loss: 0.003767473390325904\n",
      "Epoch 1, Loss: 0.004087725188583136\n",
      "Epoch 1, Loss: 0.002203661249950528\n",
      "Epoch 1, Loss: 0.002677368000149727\n",
      "Epoch 1, Loss: 0.002777575748041272\n",
      "Epoch 1, Loss: 0.005443344358354807\n",
      "Epoch 1, Loss: 0.0026983616407960653\n",
      "Epoch 1, Loss: 0.0029741027392446995\n",
      "Epoch 1, Loss: 0.0020641100127249956\n",
      "Epoch 1, Loss: 0.002120745601132512\n",
      "Epoch 1, Loss: 0.0022656628862023354\n",
      "Epoch 1, Loss: 0.0038940124213695526\n",
      "Epoch 1, Loss: 0.0034023539628833532\n",
      "Epoch 1, Loss: 0.0026673024985939264\n",
      "Epoch 1, Loss: 0.007976917549967766\n",
      "Epoch 1, Loss: 0.005932916887104511\n",
      "Epoch 1, Loss: 0.003328657476231456\n",
      "Epoch 1, Loss: 0.0021508317440748215\n",
      "Epoch 1, Loss: 0.0022237361408770084\n",
      "Epoch 1, Loss: 0.014087262563407421\n",
      "Epoch 1, Loss: 0.003282305784523487\n",
      "Epoch 1, Loss: 0.0024773881305009127\n",
      "Epoch 1, Loss: 0.002420886652544141\n",
      "Epoch 1, Loss: 0.0020154977682977915\n",
      "Epoch 1, Loss: 0.0022072528954595327\n",
      "Epoch 1, Loss: 0.0018267484847456217\n",
      "Epoch 1, Loss: 0.0031772127840667963\n",
      "Epoch 1, Loss: 0.00396339688450098\n",
      "Epoch 1, Loss: 0.00181000295560807\n",
      "Epoch 1, Loss: 0.00280518620274961\n",
      "Epoch 1, Loss: 0.004579512402415276\n",
      "Epoch 1, Loss: 0.0022826336789876223\n",
      "Epoch 1, Loss: 0.0024012133944779634\n",
      "Epoch 1, Loss: 0.001459666294977069\n",
      "Epoch 1, Loss: 0.0017628426430746913\n",
      "Epoch 1, Loss: 0.003971110098063946\n",
      "Epoch 1, Loss: 0.0024558957666158676\n",
      "Epoch 1, Loss: 0.003853379050269723\n",
      "Epoch 1, Loss: 0.002408260013908148\n",
      "Epoch 1, Loss: 0.0027678743936121464\n",
      "Epoch 1, Loss: 0.002271341159939766\n",
      "Epoch 1, Loss: 0.001733741839416325\n",
      "Epoch 1, Loss: 0.004007657524198294\n",
      "Epoch 1, Loss: 0.0024185164365917444\n",
      "Epoch 1, Loss: 0.0020062404219061136\n",
      "Epoch 1, Loss: 0.002392832888290286\n",
      "Epoch 1, Loss: 0.002168586477637291\n",
      "Epoch 1, Loss: 0.0031563753727823496\n",
      "Epoch 1, Loss: 0.002410956658422947\n",
      "Epoch 1, Loss: 0.0019302914151921868\n",
      "Epoch 1, Loss: 0.0035645312163978815\n",
      "Epoch 1, Loss: 0.0020009861327707767\n",
      "Epoch 1, Loss: 0.001776684308424592\n",
      "Epoch 1, Loss: 0.0016256149392575026\n",
      "Epoch 1, Loss: 0.002227279357612133\n",
      "Epoch 1, Loss: 0.0020606054458767176\n",
      "Epoch 1, Loss: 0.00188271957449615\n",
      "Epoch 1, Loss: 0.0015904962783679366\n",
      "Epoch 1, Loss: 0.003152760211378336\n",
      "Epoch 1, Loss: 0.001432050601579249\n",
      "Epoch 1, Loss: 0.001967153511941433\n",
      "Epoch 1, Loss: 0.0024527059867978096\n",
      "Epoch 1, Loss: 0.0018803372513502836\n",
      "Epoch 1, Loss: 0.0026731733232736588\n",
      "Epoch 1, Loss: 0.0023179391864687204\n",
      "Epoch 1, Loss: 0.0025841938331723213\n",
      "Epoch 1, Loss: 0.0019448520615696907\n",
      "Epoch 1, Loss: 0.0019585147965699434\n",
      "Epoch 1, Loss: 0.0016373158432543278\n",
      "Epoch 1, Loss: 0.002380800200626254\n",
      "Epoch 1, Loss: 0.0038363554049283266\n",
      "Epoch 1, Loss: 0.0022328097838908434\n",
      "Epoch 1, Loss: 0.0021322749089449644\n",
      "Epoch 1, Loss: 0.003436315106227994\n",
      "Epoch 1, Loss: 0.0018071882659569383\n",
      "Epoch 1, Loss: 0.002456104848533869\n",
      "Epoch 1, Loss: 0.0020314441062510014\n",
      "Epoch 1, Loss: 0.0021428046748042107\n",
      "Epoch 1, Loss: 0.00197983393445611\n",
      "Epoch 1, Loss: 0.0015511325327679515\n",
      "Epoch 1, Loss: 0.0020798095501959324\n",
      "Epoch 1, Loss: 0.002015989273786545\n",
      "Epoch 1, Loss: 0.0022109858691692352\n",
      "Epoch 1, Loss: 0.0016491621499881148\n",
      "Epoch 1, Loss: 0.0016747073968872428\n",
      "Epoch 1, Loss: 0.001945642288774252\n",
      "Epoch 1, Loss: 0.0029658228158950806\n",
      "Epoch 1, Loss: 0.001614979701116681\n",
      "Epoch 1, Loss: 0.0013890278059989214\n",
      "Epoch 1, Loss: 0.001922964584082365\n",
      "Epoch 1, Loss: 0.002096600364893675\n",
      "Epoch 2, Loss: 0.0018409522017464042\n",
      "Epoch 2, Loss: 0.0025693823117762804\n",
      "Epoch 2, Loss: 0.00195822911337018\n",
      "Epoch 2, Loss: 0.0013866022927686572\n",
      "Epoch 2, Loss: 0.0013990190345793962\n",
      "Epoch 2, Loss: 0.001975739374756813\n",
      "Epoch 2, Loss: 0.0017409001011401415\n",
      "Epoch 2, Loss: 0.0017758533358573914\n",
      "Epoch 2, Loss: 0.0018580491887405515\n",
      "Epoch 2, Loss: 0.002062617801129818\n",
      "Epoch 2, Loss: 0.0014617876149713993\n",
      "Epoch 2, Loss: 0.0018637275788933039\n",
      "Epoch 2, Loss: 0.0036616534925997257\n",
      "Epoch 2, Loss: 0.0013833799166604877\n",
      "Epoch 2, Loss: 0.0013617565855383873\n",
      "Epoch 2, Loss: 0.0021926164627075195\n",
      "Epoch 2, Loss: 0.001684715854935348\n",
      "Epoch 2, Loss: 0.0014043739065527916\n",
      "Epoch 2, Loss: 0.002586086979135871\n",
      "Epoch 2, Loss: 0.001780432416126132\n",
      "Epoch 2, Loss: 0.0020957456436008215\n",
      "Epoch 2, Loss: 0.0019015750149264932\n",
      "Epoch 2, Loss: 0.002269849879667163\n",
      "Epoch 2, Loss: 0.0014626020565629005\n",
      "Epoch 2, Loss: 0.0017479135422036052\n",
      "Epoch 2, Loss: 0.002064639702439308\n",
      "Epoch 2, Loss: 0.0030368708539754152\n",
      "Epoch 2, Loss: 0.001640701200813055\n",
      "Epoch 2, Loss: 0.001945221098139882\n",
      "Epoch 2, Loss: 0.002296052174642682\n",
      "Epoch 2, Loss: 0.0030667667742818594\n",
      "Epoch 2, Loss: 0.0015829198528081179\n",
      "Epoch 2, Loss: 0.001859829993918538\n",
      "Epoch 2, Loss: 0.0013802687171846628\n",
      "Epoch 2, Loss: 0.0020466530695557594\n",
      "Epoch 2, Loss: 0.003065100172534585\n",
      "Epoch 2, Loss: 0.0020581865683197975\n",
      "Epoch 2, Loss: 0.0019135307520627975\n",
      "Epoch 2, Loss: 0.003996080718934536\n",
      "Epoch 2, Loss: 0.0020955761428922415\n",
      "Epoch 2, Loss: 0.002434423193335533\n",
      "Epoch 2, Loss: 0.0024650059640407562\n",
      "Epoch 2, Loss: 0.0011334116570651531\n",
      "Epoch 2, Loss: 0.0020557502284646034\n",
      "Epoch 2, Loss: 0.0014820625074207783\n",
      "Epoch 2, Loss: 0.0021684716921299696\n",
      "Epoch 2, Loss: 0.0014808743726462126\n",
      "Epoch 2, Loss: 0.002052093157544732\n",
      "Epoch 2, Loss: 0.0019804430194199085\n",
      "Epoch 2, Loss: 0.0014799272175878286\n",
      "Epoch 2, Loss: 0.0013711204519495368\n",
      "Epoch 2, Loss: 0.002306482056155801\n",
      "Epoch 2, Loss: 0.001948751276358962\n",
      "Epoch 2, Loss: 0.0030008817557245493\n",
      "Epoch 2, Loss: 0.002413953887298703\n",
      "Epoch 2, Loss: 0.0016150876181200147\n",
      "Epoch 2, Loss: 0.0018378524109721184\n",
      "Epoch 2, Loss: 0.0020994036458432674\n",
      "Epoch 2, Loss: 0.001557832583785057\n",
      "Epoch 2, Loss: 0.002028043381869793\n",
      "Epoch 2, Loss: 0.0016409391537308693\n",
      "Epoch 2, Loss: 0.0012350871693342924\n",
      "Epoch 2, Loss: 0.0016456343000754714\n",
      "Epoch 2, Loss: 0.0015802537091076374\n",
      "Epoch 2, Loss: 0.00140806520357728\n",
      "Epoch 2, Loss: 0.0019411034882068634\n",
      "Epoch 2, Loss: 0.0017735282890498638\n",
      "Epoch 2, Loss: 0.0015129329403862357\n",
      "Epoch 2, Loss: 0.0019750907085835934\n",
      "Epoch 2, Loss: 0.002107164589688182\n",
      "Epoch 2, Loss: 0.0028112290892750025\n",
      "Epoch 2, Loss: 0.0020864345133304596\n",
      "Epoch 2, Loss: 0.0016866229707375169\n",
      "Epoch 2, Loss: 0.001751320785842836\n",
      "Epoch 2, Loss: 0.0021321894600987434\n",
      "Epoch 2, Loss: 0.0020469487644732\n",
      "Epoch 2, Loss: 0.001505805877968669\n",
      "Epoch 2, Loss: 0.0013326407643035054\n",
      "Epoch 2, Loss: 0.002541752764955163\n",
      "Epoch 2, Loss: 0.0016404105117544532\n",
      "Epoch 2, Loss: 0.0017302102642133832\n",
      "Epoch 2, Loss: 0.0018369447207078338\n",
      "Epoch 2, Loss: 0.0012901112204417586\n",
      "Epoch 2, Loss: 0.0017957610543817282\n",
      "Epoch 2, Loss: 0.0020553325302898884\n",
      "Epoch 2, Loss: 0.0013394546695053577\n",
      "Epoch 2, Loss: 0.0019431939581409097\n",
      "Epoch 2, Loss: 0.002574935555458069\n",
      "Epoch 2, Loss: 0.0019378401339054108\n",
      "Epoch 2, Loss: 0.0018046896439045668\n",
      "Epoch 2, Loss: 0.0016617137007415295\n",
      "Epoch 2, Loss: 0.0015297717181965709\n",
      "Epoch 2, Loss: 0.001349753700196743\n",
      "Epoch 2, Loss: 0.001352764549665153\n",
      "Epoch 2, Loss: 0.00179636524990201\n",
      "Epoch 2, Loss: 0.0014107408933341503\n",
      "Epoch 2, Loss: 0.0016995902406051755\n",
      "Epoch 2, Loss: 0.001396283390931785\n",
      "Epoch 2, Loss: 0.002359182806685567\n",
      "Epoch 2, Loss: 0.0014001510571688414\n",
      "Epoch 2, Loss: 0.0015587484231218696\n",
      "Epoch 2, Loss: 0.0019112643785774708\n",
      "Epoch 2, Loss: 0.0015461280709132552\n",
      "Epoch 2, Loss: 0.0017010591691359878\n",
      "Epoch 2, Loss: 0.0017389446729794145\n",
      "Epoch 2, Loss: 0.0023128334432840347\n",
      "Epoch 2, Loss: 0.0017883696127682924\n",
      "Epoch 2, Loss: 0.0029649038333445787\n",
      "Epoch 2, Loss: 0.003224125597625971\n",
      "Epoch 2, Loss: 0.0011466756695881486\n",
      "Epoch 2, Loss: 0.0017957438249140978\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# 加載數據\n",
    "raw_data = pd.read_csv('train_2022.csv')\n",
    "\n",
    "# 轉換 LABEL 到文本形式\n",
    "raw_data['LABEL'] = raw_data['LABEL'].map({0: \"negative\", 1: \"positive\"})\n",
    "\n",
    "# 創建 T5 格式的輸入\n",
    "raw_data['T5_INPUT'] = \"classify sentiment: \" + raw_data['TEXT']\n",
    "raw_data['T5_OUTPUT'] = raw_data['LABEL']\n",
    "\n",
    "# 切分數據為訓練集和驗證集\n",
    "train_data, val_data = train_test_split(raw_data, test_size=0.1, random_state=42)  # 以10%的數據作為驗證集\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        input_ids = self.tokenizer.encode(item['T5_INPUT'], \n",
    "                                          max_length=self.max_length, \n",
    "                                          truncation=True, \n",
    "                                          padding='max_length', \n",
    "                                          return_tensors='pt').squeeze()\n",
    "        labels = self.tokenizer.encode(item['T5_OUTPUT'], \n",
    "                                       max_length=self.max_length, \n",
    "                                       truncation=True, \n",
    "                                       padding='max_length', \n",
    "                                       return_tensors='pt').squeeze()\n",
    "        return input_ids, labels\n",
    "\n",
    "# 根據切分後的數據集創建 DataLoader\n",
    "train_dataset = SentimentDataset(train_data, tokenizer)\n",
    "val_dataset = SentimentDataset(val_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 設定設備\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# 訓練循環\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 訓練模型\n",
    "model.train()\n",
    "for epoch in range(3):  # 使用3個epoch\n",
    "    for input_ids, labels in train_loader:\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "\n",
    "        # 前向傳播\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # 反向傳播和優化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_loader:\n",
    "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "            outputs = model.generate(input_ids=input_ids)\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            \n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return classification_report(true_labels, predicted_labels, target_names=['negative', 'positive'], output_dict=True)\n",
    "\n",
    "# 在驗證集上評估模型\n",
    "report = evaluate(model, val_loader)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3be2a-5546-4ab3-8516-7dc9afa9298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 加載測試數據\n",
    "test_data = pd.read_csv('test_no_answer_2022.csv')\n",
    "\n",
    "# 創建 T5 格式的輸入\n",
    "test_data['T5_INPUT'] = \"classify sentiment: \" + test_data['TEXT']\n",
    "\n",
    "# 定義一個 Dataset 用於測試數據\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        input_ids = self.tokenizer.encode(item['T5_INPUT'], \n",
    "                                          max_length=self.max_length, \n",
    "                                          truncation=True, \n",
    "                                          padding='max_length', \n",
    "                                          return_tensors='pt').squeeze()\n",
    "        return input_ids\n",
    "\n",
    "# 創建 DataLoader\n",
    "test_dataset = PredictionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab190828-74e3-40db-bf6b-9aed0d82473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids in test_loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            outputs = model.generate(input_ids=input_ids)\n",
    "            decoded_preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            predictions.extend(decoded_preds)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 生成預測結果\n",
    "predictions = generate_predictions(model, test_loader)\n",
    "\n",
    "# 打印一些預測結果看看\n",
    "for i, text in enumerate(test_data['TEXT'].head(5)):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350aa580-3c40-46b2-a4ec-c86ddc02c890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdc909-0f60-40f5-9257-5e88a98c4436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3073819-7e88-40d0-8c1b-a9890e4a2e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147409d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2f1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fa2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbab50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51960b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
