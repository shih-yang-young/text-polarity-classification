{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2fbf8f-c44e-4f7a-89f2-12867023cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_2022 = pd.read_csv('train_2022.csv')\n",
    "data_augmentation_chatGPT = pd.read_csv('data_augmentation_chatGPT.csv')\n",
    "data_augmentation_random_2_words = pd.read_csv('data_augmentation_random_2_words.csv')\n",
    "data_augmentation_random_3_words = pd.read_csv('data_augmentation_random_3_words.csv')\n",
    "translated_en_data = pd.read_csv('translated_en_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0596842e-f927-47cf-b188-321e4a56b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>director dirk shafer and co-writer greg hinton...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a charming , quirky and leisurely paced scotti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the price was good ,  and came quickly though ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i was looking forward to this game for a coupl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arguably the year 's silliest and most incoher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>painful to watch , but viewers willing to take...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>a byzantine melodrama that stimulates the high...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>he 's super spy !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>but this stuff will fall apart after only a fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>the aftertaste is so overpowering i had to bru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id                                               TEXT  LABEL\n",
       "0         0  director dirk shafer and co-writer greg hinton...      0\n",
       "1         1  a charming , quirky and leisurely paced scotti...      1\n",
       "2         2  the price was good ,  and came quickly though ...      1\n",
       "3         3  i was looking forward to this game for a coupl...      0\n",
       "4         4  arguably the year 's silliest and most incoher...      0\n",
       "..      ...                                                ...    ...\n",
       "995     995  painful to watch , but viewers willing to take...      1\n",
       "996     996  a byzantine melodrama that stimulates the high...      1\n",
       "997     997                                  he 's super spy !      1\n",
       "998     998  but this stuff will fall apart after only a fe...      0\n",
       "999     999  the aftertaste is so overpowering i had to bru...      0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([train_2022], ignore_index=True)\n",
    "merged_data = merged_data[:1000]\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13389a26-bd7e-4c9f-8179-6daaaa899f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4950263500213623\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 確認是否有可用的 CUDA 設備，並設定使用的設備\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "\n",
    "# 載入預訓練的 tokenizer 和模型，這裡指定了 assemblyai 提供的 BERT large 模型\n",
    "tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "model.to(device)\n",
    "\n",
    "# 轉換文本為 token IDs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids'][0]\n",
    "\n",
    "merged_data['input_ids'] = merged_data['TEXT'].apply(tokenize_text)\n",
    "\n",
    "# 轉換成可以輸入模型的格式，並移動到 CUDA 設備上\n",
    "inputs = pad_sequence(merged_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "labels = torch.tensor(merged_data['LABEL'].tolist()).to(device)\n",
    "\n",
    "# 將資料拆分為訓練集和測試集\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建 PyTorch DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# 定義 optimizer 和損失函數\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 訓練模型\n",
    "model.train()\n",
    "for epoch in range(3):  # 進行三個 epoch 的訓練\n",
    "    for batch in train_loader:\n",
    "        b_input_ids, b_labels = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "# 評估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_inputs)\n",
    "    predicted_labels = torch.argmax(test_outputs.logits, dim=1)\n",
    "\n",
    "# 產生分類報告\n",
    "report = classification_report(test_labels.cpu(), predicted_labels.cpu())\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
