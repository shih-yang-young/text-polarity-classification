{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2fbf8f-c44e-4f7a-89f2-12867023cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_2022 = pd.read_csv('train_2022.csv')\n",
    "data_augmentation_chatGPT = pd.read_csv('data_augmentation_chatGPT.csv')\n",
    "data_augmentation_random_2_words = pd.read_csv('data_augmentation_random_2_words.csv')\n",
    "data_augmentation_random_3_words = pd.read_csv('data_augmentation_random_3_words.csv')\n",
    "translated_en_data = pd.read_csv('translated_en_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0596842e-f927-47cf-b188-321e4a56b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>director dirk shafer and co-writer greg hinton...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a charming , quirky and leisurely paced scotti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the price was good ,  and came quickly though ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i was looking forward to this game for a coupl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arguably the year 's silliest and most incoher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>anyway i recommend this one for its price and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>it seems to be of very good quality in its bui...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>... there are enough moments of heartbreaking ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>they get into the corners as described and are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>it extends the writings of jean genet and john...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>liman , of swingers and go , makes his big-bud...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>a sermonizing and lifeless paean to teenage du...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>the issue of faith is not explored very deeply</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>armada lacks the epic scope of similar games l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>the people in dogtown and z-boys are so funny ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>bad company leaves a bad taste , not only beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>scarlet diva has a voyeuristic tug , but all i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>with this i say i work giving support to the u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>this meter is technology from a decade ago .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>they were huge ,  yet the same size in the lea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>it never fails to engage us .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>it worked great for the first couple of weeks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>as lo-fi as the special effects are , the folk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>either than or the developers decided to do th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>it 's neither as romantic nor as thrilling as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>will update this review should it meet a simil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>i cannot recommend this product for anyone try...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>but this time there 's some mold on the gold .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>i won t give this to the new puppy i m getting .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>i have never had a pleasant experience with th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>pretty much all i ask for in a grinder .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>snug fit ,  with all the buttons and holes per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>also ,  it creates more static than the one i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>this road movie gives you emotional whiplash ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>stars matthew perry and elizabeth hurley illic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>a triumph , relentless and beautiful in its do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>a very witty take on change , risk and romance...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>perfect size for preparing dishes . it really ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>it keeps the air clean and nice fresh smelling .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>i do n't have an i am sam clue .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>but the back side looks nice as well .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>a dreary , incoherent , self-indulgent mess of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>think of it as a sort of comfort food for the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>this keeps the cord out of the way and above t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>what will , most likely , turn out to be the m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>item arrived in num_num days in bulk packaging...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>a chaotic panorama that 's too busy flying a l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>and ,  there were many things we liked about t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>what makes the movie a comedy is the way it av...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id                                               TEXT  LABEL\n",
       "0        0  director dirk shafer and co-writer greg hinton...      0\n",
       "1        1  a charming , quirky and leisurely paced scotti...      1\n",
       "2        2  the price was good ,  and came quickly though ...      1\n",
       "3        3  i was looking forward to this game for a coupl...      0\n",
       "4        4  arguably the year 's silliest and most incoher...      0\n",
       "5        5  emerges as something rare , an issue movie tha...      1\n",
       "6        6  anyway i recommend this one for its price and ...      1\n",
       "7        7  it seems to be of very good quality in its bui...      1\n",
       "8        8  ... there are enough moments of heartbreaking ...      1\n",
       "9        9  they get into the corners as described and are...      1\n",
       "10      10  it extends the writings of jean genet and john...      1\n",
       "11      11  liman , of swingers and go , makes his big-bud...      0\n",
       "12      12  a sermonizing and lifeless paean to teenage du...      0\n",
       "13      13     the issue of faith is not explored very deeply      0\n",
       "14      14  armada lacks the epic scope of similar games l...      0\n",
       "15      15  the people in dogtown and z-boys are so funny ...      1\n",
       "16      16  bad company leaves a bad taste , not only beca...      0\n",
       "17      17  scarlet diva has a voyeuristic tug , but all i...      0\n",
       "18      18  with this i say i work giving support to the u...      0\n",
       "19      19       this meter is technology from a decade ago .      0\n",
       "20      20  they were huge ,  yet the same size in the lea...      0\n",
       "21      21                      it never fails to engage us .      1\n",
       "22      22  it worked great for the first couple of weeks ...      0\n",
       "23      23  as lo-fi as the special effects are , the folk...      1\n",
       "24      24  either than or the developers decided to do th...      0\n",
       "25      25  it 's neither as romantic nor as thrilling as ...      0\n",
       "26      26  will update this review should it meet a simil...      1\n",
       "27      27  i cannot recommend this product for anyone try...      0\n",
       "28      28     but this time there 's some mold on the gold .      0\n",
       "29      29   i won t give this to the new puppy i m getting .      0\n",
       "30      30  i have never had a pleasant experience with th...      1\n",
       "31      31           pretty much all i ask for in a grinder .      1\n",
       "32      32  snug fit ,  with all the buttons and holes per...      1\n",
       "33      33  also ,  it creates more static than the one i ...      0\n",
       "34      34  this road movie gives you emotional whiplash ,...      1\n",
       "35      35  stars matthew perry and elizabeth hurley illic...      0\n",
       "36      36  a triumph , relentless and beautiful in its do...      1\n",
       "37      37  a very witty take on change , risk and romance...      1\n",
       "38      38  perfect size for preparing dishes . it really ...      1\n",
       "39      39   it keeps the air clean and nice fresh smelling .      1\n",
       "40      40                   i do n't have an i am sam clue .      0\n",
       "41      41             but the back side looks nice as well .      1\n",
       "42      42  a dreary , incoherent , self-indulgent mess of...      0\n",
       "43      43  think of it as a sort of comfort food for the ...      1\n",
       "44      44  this keeps the cord out of the way and above t...      1\n",
       "45      45  what will , most likely , turn out to be the m...      0\n",
       "46      46  item arrived in num_num days in bulk packaging...      1\n",
       "47      47  a chaotic panorama that 's too busy flying a l...      0\n",
       "48      48  and ,  there were many things we liked about t...      0\n",
       "49      49  what makes the movie a comedy is the way it av...      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([train_2022,data_augmentation_chatGPT], ignore_index=True)\n",
    "merged_data = merged_data[:50]\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13389a26-bd7e-4c9f-8179-6daaaa899f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.038996696472168\n",
      "Epoch 2, Loss: 0.415835440158844\n",
      "Epoch 3, Loss: 0.19637218117713928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.58      0.58      0.58        10\n",
      "weighted avg       0.60      0.60      0.60        10\n",
      "\n",
      "CPU times: total: 3min 28s\n",
      "Wall time: 52.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 確認是否有可用的 CUDA 設備，並設定使用的設備\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "\n",
    "# 載入預訓練的 tokenizer 和模型，這裡指定了 assemblyai 提供的 BERT large 模型\n",
    "tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "model.to(device)\n",
    "\n",
    "# 轉換文本為 token IDs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids'][0]\n",
    "\n",
    "merged_data['input_ids'] = merged_data['TEXT'].apply(tokenize_text)\n",
    "\n",
    "# 轉換成可以輸入模型的格式，並移動到 CUDA 設備上\n",
    "inputs = pad_sequence(merged_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "labels = torch.tensor(merged_data['LABEL'].tolist()).to(device)\n",
    "\n",
    "# 將資料拆分為訓練集和測試集\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建 PyTorch DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 定義 optimizer 和損失函數\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 訓練模型\n",
    "model.train()\n",
    "for epoch in range(3):  # 進行三個 epoch 的訓練\n",
    "    for batch in train_loader:\n",
    "        b_input_ids, b_labels = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "# 評估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_inputs)\n",
    "    predicted_labels = torch.argmax(test_outputs.logits, dim=1)\n",
    "\n",
    "# 產生分類報告\n",
    "report = classification_report(test_labels.cpu(), predicted_labels.cpu())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff062e1-b0cd-469c-a44f-9b2e5e6fe4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "def export_csv(df,name):\n",
    "  now = datetime.datetime.now().astimezone(pytz.timezone('Asia/Taipei'))\n",
    "  formatted_time = now.strftime('%Y%m%d')\n",
    "  df.to_csv('result/'+ formatted_time + '_' + name + \".csv\", index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd532eb5-cce6-4414-b924-90a3cb3bb9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    TEXT  PREDICTED_LABEL\n",
      "0       good to know if you can t find these elsewhere .                1\n",
      "1      love it !  the grill plates come out and pop i...                1\n",
      "2      i m convinced this was a poorly executed refur...                0\n",
      "3      i would never have complained about that if it...                1\n",
      "4      the photo shows the same whole ,  large candie...                1\n",
      "...                                                  ...              ...\n",
      "10995             i didn t quite get it the first time .                0\n",
      "10996  i ve tried installing with and without the oem...                0\n",
      "10997  i was parked at a truck stop in the cincinnati...                0\n",
      "10998  i recently bought this case after seeing some ...                1\n",
      "10999  the keyboard types only % of the time and the ...                0\n",
      "\n",
      "[11000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 載入測試數據\n",
    "test_data = pd.read_csv('test_no_answer_2022.csv')\n",
    "\n",
    "# 轉換測試數據文本為模型的輸入格式\n",
    "test_inputs = test_data['TEXT'].apply(tokenize_text).tolist()\n",
    "\n",
    "# 將輸入數據轉換為 PyTorch 張量並移動到 CUDA 設備上（如果可用）\n",
    "test_inputs = pad_sequence(test_inputs, batch_first=True).to(device)\n",
    "\n",
    "# 使用訓練好的模型進行預測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_inputs)\n",
    "    predicted_labels = torch.argmax(test_outputs.logits, dim=1)\n",
    "\n",
    "# 將預測結果轉換為 NumPy 陣列\n",
    "predicted_labels = predicted_labels.cpu().numpy()\n",
    "\n",
    "# 將預測結果添加到測試數據中\n",
    "test_data['PREDICTED_LABEL'] = predicted_labels\n",
    "\n",
    "# 打印測試數據及其對應的預測結果\n",
    "print(test_data[['TEXT', 'PREDICTED_LABEL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc51cb81-30d0-4f9c-8e61-9f270692546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row_id                                               TEXT  LABEL\n",
      "0           0   good to know if you can t find these elsewhere .      1\n",
      "1           1  love it !  the grill plates come out and pop i...      1\n",
      "2           2  i m convinced this was a poorly executed refur...      0\n",
      "3           3  i would never have complained about that if it...      1\n",
      "4           4  the photo shows the same whole ,  large candie...      1\n",
      "...       ...                                                ...    ...\n",
      "10995   10995             i didn t quite get it the first time .      0\n",
      "10996   10996  i ve tried installing with and without the oem...      0\n",
      "10997   10997  i was parked at a truck stop in the cincinnati...      0\n",
      "10998   10998  i recently bought this case after seeing some ...      1\n",
      "10999   10999  the keyboard types only % of the time and the ...      0\n",
      "\n",
      "[11000 rows x 3 columns]\n",
      "CPU times: total: 29.9 s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 設定 device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 載入預測資料集\n",
    "test_data = pd.read_csv('test_no_answer_2022.csv')\n",
    "\n",
    "# 使用 tokenizer 將文本轉換為 token IDs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, return_tensors='pt')['input_ids'][0]\n",
    "\n",
    "test_data['input_ids'] = test_data['TEXT'].apply(tokenize_text)\n",
    "\n",
    "# 轉換成可以輸入模型的格式\n",
    "test_inputs = pad_sequence(test_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "\n",
    "# 創建 PyTorch DataLoader\n",
    "test_dataset = TensorDataset(test_inputs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# 使用模型進行預測\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        outputs = model(inputs[0])  # 確保 inputs[0] 已在 GPU 上\n",
    "        predicted_labels = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "        predictions.extend(predicted_labels)\n",
    "\n",
    "# 將預測結果添加到測試數據集中\n",
    "test_data['LABEL'] = predictions\n",
    "# 保存預測結果到 CSV 文件\n",
    "# 需要你自己定義 export_csv 函數，或使用 pandas 的 to_csv 方法\n",
    "export_csv(test_data[['row_id', 'LABEL']], 'bert_large_uncased_sst2')\n",
    "# 打印預測結果\n",
    "print(test_data[['row_id','TEXT', 'LABEL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0187c-12cb-46cc-b24a-095713b3f807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e3496-4f54-4e65-af66-a8b4e247f050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa80c8-184c-4d67-a960-7bed4f5f1313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0db879e-5ea2-48f2-8a3f-434d634184f5",
   "metadata": {},
   "source": [
    "# 多加一層MLP 用那層tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979ccf64-0eed-4da4-844f-d5cf8630e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.29902413487434387\n",
      "Epoch 2, Loss: 0.3729929029941559\n",
      "Epoch 3, Loss: 0.9795500636100769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       416\n",
      "           1       0.79      0.79      0.79       384\n",
      "\n",
      "    accuracy                           0.80       800\n",
      "   macro avg       0.80      0.80      0.80       800\n",
      "weighted avg       0.80      0.80      0.80       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# # 設定設備\n",
    "# device = \"cpu\"\n",
    "\n",
    "# # 載入預訓練的 tokenizer 和模型\n",
    "# tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "\n",
    "# # 凍結預訓練層的權重\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # 新增一個自定義層，只有這層是可訓練的\n",
    "# num_labels = 2  # 假設是一個二分類問題\n",
    "# custom_classifier = nn.Sequential(\n",
    "#     nn.Linear(model.classifier.in_features, num_labels)\n",
    "# )\n",
    "# custom_classifier.to(device)\n",
    "\n",
    "# # 將自定義層加到模型上\n",
    "# model.classifier = custom_classifier\n",
    "\n",
    "# # 轉換文本為 token IDs\n",
    "# def tokenize_text(text):\n",
    "#     return tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids'][0]\n",
    "\n",
    "# merged_data['input_ids'] = merged_data['TEXT'].apply(tokenize_text)\n",
    "# inputs = pad_sequence(merged_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "# labels = torch.tensor(merged_data['LABEL'].tolist()).to(device)\n",
    "\n",
    "# # 將資料拆分為訓練集和測試集\n",
    "# train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 創建 DataLoader\n",
    "# train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# # 定義 optimizer 只針對新層\n",
    "# optimizer = AdamW(model.classifier.parameters(), lr=2e-5)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# # 訓練模型\n",
    "# model.train()\n",
    "# for epoch in range(3):\n",
    "#     for b_input_ids, b_labels in train_loader:\n",
    "#         model.zero_grad()\n",
    "#         outputs = model(b_input_ids, labels=b_labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# # 評估模型\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     test_outputs = model(test_inputs)\n",
    "#     predicted_labels = torch.argmax(test_outputs.logits, dim=1)\n",
    "\n",
    "# # 產生分類報告\n",
    "# report = classification_report(test_labels.cpu(), predicted_labels.cpu())\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c50d4-b810-415b-9ec6-b5cd434e9871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c18293-a5af-4e61-9983-5515be0c49d9",
   "metadata": {},
   "source": [
    "# 直接使用 model 做預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4343ce57-a761-49fe-a083-89127d62eb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79        49\n",
      "           1       0.80      0.78      0.79        51\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.79      0.79      0.79       100\n",
      "weighted avg       0.79      0.79      0.79       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "# from torch.nn.functional import softmax\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # 設置設備\n",
    "# device = \"cpu\"\n",
    "\n",
    "# # 載入預訓練的 tokenizer 和模型\n",
    "# tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# # 轉換文本為模型輸入格式\n",
    "# def prepare_data(texts):\n",
    "#     encoding = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "#     return encoding['input_ids'], encoding['attention_mask']\n",
    "\n",
    "# # 使用模型進行批次預測\n",
    "# def predict(texts):\n",
    "#     input_ids, attention_mask = prepare_data(texts)\n",
    "#     input_ids = input_ids.to(device)\n",
    "#     attention_mask = attention_mask.to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#     logits = outputs.logits\n",
    "#     probabilities = softmax(logits, dim=1)\n",
    "#     return probabilities\n",
    "\n",
    "# # 預測情感\n",
    "# probabilities = predict(merged_data['TEXT'].tolist())\n",
    "# predicted_labels = torch.argmax(probabilities, dim=1).numpy()\n",
    "\n",
    "# # 實際標籤\n",
    "# real_labels = merged_data['LABEL'].tolist()\n",
    "\n",
    "# # 計算分類報告\n",
    "# report = classification_report(real_labels, predicted_labels)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b4af5-56b6-468f-9c4a-e5f3a5061c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757042a-d720-43d9-ba4d-e1d8971764f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
