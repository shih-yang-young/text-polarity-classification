{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2fbf8f-c44e-4f7a-89f2-12867023cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_2022 = pd.read_csv('train_2022.csv')\n",
    "data_augmentation_chatGPT = pd.read_csv('data_augmentation_chatGPT.csv')\n",
    "data_augmentation_random_2_words = pd.read_csv('data_augmentation_random_2_words.csv')\n",
    "data_augmentation_random_3_words = pd.read_csv('data_augmentation_random_3_words.csv')\n",
    "translated_en_data = pd.read_csv('translated_en_data.csv')\n",
    "amazon_short_text_data = pd.read_csv('amazon_short_text_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79aafd72-b41e-4ad1-a342-0ef6ab86bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Worst! A complete waste of time. Typograph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sizes recomended in the size chart are not rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Nothing you don't already know If you have eve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Doesn't work on a Mac It clearly says on line ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Alaska sourdough REad most of the book while v...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>0</td>\n",
       "      <td>Too hard to read. I returned it. The print is ...</td>\n",
       "      <td>7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7107</th>\n",
       "      <td>0</td>\n",
       "      <td>LARGE PRINT BIBLE THE LARGE PRINT WORDS VERY L...</td>\n",
       "      <td>7107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>0</td>\n",
       "      <td>Lol the Bible sucks Responsible for hate, bigo...</td>\n",
       "      <td>7110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>0</td>\n",
       "      <td>boring book It's a really boring book, I am su...</td>\n",
       "      <td>7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>0</td>\n",
       "      <td>didn't do much for me I honestly wouldn't reco...</td>\n",
       "      <td>7112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LABEL                                               TEXT  row_id\n",
       "0         0  The Worst! A complete waste of time. Typograph...       0\n",
       "1         0  sizes recomended in the size chart are not rea...       1\n",
       "2         0  Nothing you don't already know If you have eve...       2\n",
       "3         0  Doesn't work on a Mac It clearly says on line ...       3\n",
       "4         1  Alaska sourdough REad most of the book while v...       4\n",
       "...     ...                                                ...     ...\n",
       "7106      0  Too hard to read. I returned it. The print is ...    7106\n",
       "7107      0  LARGE PRINT BIBLE THE LARGE PRINT WORDS VERY L...    7107\n",
       "7110      0  Lol the Bible sucks Responsible for hate, bigo...    7110\n",
       "7111      0  boring book It's a really boring book, I am su...    7111\n",
       "7112      0  didn't do much for me I honestly wouldn't reco...    7112\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = amazon_short_text_data.groupby('LABEL').head(3000)\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cc4277-323d-460a-999e-6eb78d4f56b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>director dirk shafer and co-writer greg hinton...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a charming , quirky and leisurely paced scotti...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the price was good ,  and came quickly though ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was looking forward to this game for a coupl...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arguably the year 's silliest and most incoher...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Too hard to read. I returned it. The print is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>LARGE PRINT BIBLE THE LARGE PRINT WORDS VERY L...</td>\n",
       "      <td>0</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Lol the Bible sucks Responsible for hate, bigo...</td>\n",
       "      <td>0</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>boring book It's a really boring book, I am su...</td>\n",
       "      <td>0</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>didn't do much for me I honestly wouldn't reco...</td>\n",
       "      <td>0</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TEXT  LABEL  row_id\n",
       "0     director dirk shafer and co-writer greg hinton...      0       0\n",
       "1     a charming , quirky and leisurely paced scotti...      1       1\n",
       "2     the price was good ,  and came quickly though ...      1       2\n",
       "3     i was looking forward to this game for a coupl...      0       3\n",
       "4     arguably the year 's silliest and most incoher...      0       4\n",
       "...                                                 ...    ...     ...\n",
       "9995  Too hard to read. I returned it. The print is ...      0    9995\n",
       "9996  LARGE PRINT BIBLE THE LARGE PRINT WORDS VERY L...      0    9996\n",
       "9997  Lol the Bible sucks Responsible for hate, bigo...      0    9997\n",
       "9998  boring book It's a really boring book, I am su...      0    9998\n",
       "9999  didn't do much for me I honestly wouldn't reco...      0    9999\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([train_2022, data_augmentation_chatGPT, amazon], ignore_index=True)\n",
    "merged_data = merged_data.reset_index(drop=True)\n",
    "merged_data = merged_data.drop(columns=['row_id'])\n",
    "merged_data['row_id'] = merged_data.index\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13389a26-bd7e-4c9f-8179-6daaaa899f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1:   0%|                                                                                | 0/1000 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [05:05<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13762561976909637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [05:11<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.04803113639354706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [05:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.07380876690149307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [05:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.08239731192588806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████| 1000/1000 [05:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.01663840189576149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       987\n",
      "           1       0.94      0.91      0.93      1013\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.93      0.93      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n",
      "CPU times: total: 7min 24s\n",
      "Wall time: 27min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 確認是否有可用的 CUDA 設備，並設定使用的設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\"\n",
    "\n",
    "# 載入預訓練的 tokenizer 和模型，這裡指定了 assemblyai 提供的 BERT large 模型\n",
    "tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "model.to(device)\n",
    "\n",
    "# 轉換文本為 token IDs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, return_tensors='pt', padding=True, truncation=True)['input_ids'][0]\n",
    "\n",
    "merged_data['input_ids'] = merged_data['TEXT'].apply(tokenize_text)\n",
    "\n",
    "# 轉換成可以輸入模型的格式，並移動到 CUDA 設備上\n",
    "inputs = pad_sequence(merged_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "labels = torch.tensor(merged_data['LABEL'].tolist()).to(device)\n",
    "\n",
    "# 將資料拆分為訓練集和測試集\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建 PyTorch DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 定義 optimizer 和損失函數\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 訓練模型\n",
    "model.train()\n",
    "for epoch in range(5):  # 進行個 epoch 的訓練\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):  # 使用tqdm包裹train_loader\n",
    "        b_input_ids, b_labels = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "# 評估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_inputs)\n",
    "    predicted_labels = torch.argmax(test_outputs.logits, dim=1)\n",
    "\n",
    "# 產生分類報告\n",
    "report = classification_report(test_labels.cpu(), predicted_labels.cpu())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff062e1-b0cd-469c-a44f-9b2e5e6fe4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "def export_csv(df,name):\n",
    "  now = datetime.datetime.now().astimezone(pytz.timezone('Asia/Taipei'))\n",
    "  formatted_time = now.strftime('%Y%m%d')\n",
    "  df.to_csv('result/'+ formatted_time + '_' + name + \".csv\", index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc51cb81-30d0-4f9c-8e61-9f270692546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row_id                                               TEXT  LABEL\n",
      "0           0   good to know if you can t find these elsewhere .      1\n",
      "1           1  love it !  the grill plates come out and pop i...      1\n",
      "2           2  i m convinced this was a poorly executed refur...      0\n",
      "3           3  i would never have complained about that if it...      1\n",
      "4           4  the photo shows the same whole ,  large candie...      0\n",
      "...       ...                                                ...    ...\n",
      "10995   10995             i didn t quite get it the first time .      0\n",
      "10996   10996  i ve tried installing with and without the oem...      1\n",
      "10997   10997  i was parked at a truck stop in the cincinnati...      0\n",
      "10998   10998  i recently bought this case after seeing some ...      1\n",
      "10999   10999  the keyboard types only % of the time and the ...      0\n",
      "\n",
      "[11000 rows x 3 columns]\n",
      "CPU times: total: 58.2 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 設定 device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 載入預測資料集\n",
    "test_data = pd.read_csv('test_no_answer_2022.csv')\n",
    "\n",
    "# 使用 tokenizer 將文本轉換為 token IDs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, return_tensors='pt')['input_ids'][0]\n",
    "\n",
    "test_data['input_ids'] = test_data['TEXT'].apply(tokenize_text)\n",
    "\n",
    "# 轉換成可以輸入模型的格式\n",
    "test_inputs = pad_sequence(test_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "\n",
    "# 創建 PyTorch DataLoader\n",
    "test_dataset = TensorDataset(test_inputs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# 使用模型進行預測\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        outputs = model(inputs[0])  # 確保 inputs[0] 已在 GPU 上\n",
    "        predicted_labels = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "        predictions.extend(predicted_labels)\n",
    "\n",
    "# 將預測結果添加到測試數據集中\n",
    "test_data['LABEL'] = predictions\n",
    "# 保存預測結果到 CSV 文件\n",
    "# 需要你自己定義 export_csv 函數，或使用 pandas 的 to_csv 方法\n",
    "export_csv(test_data[['row_id', 'LABEL']], 'bert_large_uncased_sst2_Amazon_10000')\n",
    "# 打印預測結果\n",
    "print(test_data[['row_id','TEXT', 'LABEL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0187c-12cb-46cc-b24a-095713b3f807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e3496-4f54-4e65-af66-a8b4e247f050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa80c8-184c-4d67-a960-7bed4f5f1313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0db879e-5ea2-48f2-8a3f-434d634184f5",
   "metadata": {},
   "source": [
    "# 多加一層MLP 用那層tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979ccf64-0eed-4da4-844f-d5cf8630e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# # 設定設備\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # 載入預訓練的 tokenizer 和模型\n",
    "# tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "\n",
    "# # 凍結預訓練層的權重\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # 新增一個自定義層，只有這層是可訓練的\n",
    "# num_labels = 2  # 假設是一個二分類問題\n",
    "# custom_classifier = nn.Sequential(\n",
    "#     nn.Linear(model.classifier.in_features, num_labels)\n",
    "# )\n",
    "\n",
    "# # 將自定義層加到模型上\n",
    "# model.classifier = custom_classifier\n",
    "# model.to(device)  # 確保整個模型都在同一設備上\n",
    "\n",
    "# # 轉換文本為 token IDs\n",
    "# def tokenize_text(text):\n",
    "#     return tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)['input_ids'][0]\n",
    "\n",
    "# merged_data['input_ids'] = merged_data['TEXT'].apply(tokenize_text)\n",
    "# inputs = pad_sequence(merged_data['input_ids'].tolist(), batch_first=True).to(device)\n",
    "# labels = torch.tensor(merged_data['LABEL'].tolist()).to(device)\n",
    "\n",
    "# # 將資料拆分為訓練集和測試集\n",
    "# train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 創建 DataLoader\n",
    "# train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# # 定義 optimizer 只針對新層\n",
    "# optimizer = AdamW(model.classifier.parameters(), lr=2e-5)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# # 訓練模型\n",
    "# model.train()\n",
    "# for epoch in range(5):\n",
    "#     for b_input_ids, b_labels in train_loader:\n",
    "#         model.zero_grad()\n",
    "#         outputs = model(b_input_ids, labels=b_labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# # 評估模型\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     test_outputs = model(test_inputs)\n",
    "#     predicted_labels = torch.argmax(test_outputs.logits, dim=1)\n",
    "\n",
    "# # 產生分類報告\n",
    "# report = classification_report(test_labels.cpu(), predicted_labels.cpu())\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c50d4-b810-415b-9ec6-b5cd434e9871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c18293-a5af-4e61-9983-5515be0c49d9",
   "metadata": {},
   "source": [
    "# 直接使用 model 做預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4343ce57-a761-49fe-a083-89127d62eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "# from torch.nn.functional import softmax\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # 設置設備\n",
    "# device = \"cpu\"\n",
    "\n",
    "# # 載入預訓練的 tokenizer 和模型\n",
    "# tokenizer = AutoTokenizer.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('assemblyai/bert-large-uncased-sst2')\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# # 轉換文本為模型輸入格式\n",
    "# def prepare_data(texts):\n",
    "#     encoding = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "#     return encoding['input_ids'], encoding['attention_mask']\n",
    "\n",
    "# # 使用模型進行批次預測\n",
    "# def predict(texts):\n",
    "#     input_ids, attention_mask = prepare_data(texts)\n",
    "#     input_ids = input_ids.to(device)\n",
    "#     attention_mask = attention_mask.to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#     logits = outputs.logits\n",
    "#     probabilities = softmax(logits, dim=1)\n",
    "#     return probabilities\n",
    "\n",
    "# # 預測情感\n",
    "# probabilities = predict(merged_data['TEXT'].tolist())\n",
    "# predicted_labels = torch.argmax(probabilities, dim=1).numpy()\n",
    "\n",
    "# # 實際標籤\n",
    "# real_labels = merged_data['LABEL'].tolist()\n",
    "\n",
    "# # 計算分類報告\n",
    "# report = classification_report(real_labels, predicted_labels)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b4af5-56b6-468f-9c4a-e5f3a5061c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757042a-d720-43d9-ba4d-e1d8971764f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
