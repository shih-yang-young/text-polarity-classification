{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4546cbdd-f0ef-4e4c-bc9f-640d08b8b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_2022 = pd.read_csv('train_2022.csv')\n",
    "data_augmentation_chatGPT = pd.read_csv('data_augmentation_chatGPT.csv')\n",
    "data_augmentation_random_2_words = pd.read_csv('data_augmentation_random_2_words.csv')\n",
    "data_augmentation_random_3_words = pd.read_csv('data_augmentation_random_3_words.csv')\n",
    "translated_en_data = pd.read_csv('translated_en_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447964a5-b976-4c3f-810c-26f833ebc418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>director dirk shafer and co-writer greg hinton...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a charming , quirky and leisurely paced scotti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the price was good ,  and came quickly though ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i was looking forward to this game for a coupl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arguably the year 's silliest and most incoher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>1995</td>\n",
       "      <td>A creative comedy/thriller.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1996</td>\n",
       "      <td>Explores paranoia and insecurity in America's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1997</td>\n",
       "      <td>Good for power grating.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>1998</td>\n",
       "      <td>McGrath's variation on the novel crafts moving...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1999</td>\n",
       "      <td>Haneke's creepy explorations are rewarded with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id                                               TEXT  LABEL\n",
       "0          0  director dirk shafer and co-writer greg hinton...      0\n",
       "1          1  a charming , quirky and leisurely paced scotti...      1\n",
       "2          2  the price was good ,  and came quickly though ...      1\n",
       "3          3  i was looking forward to this game for a coupl...      0\n",
       "4          4  arguably the year 's silliest and most incoher...      0\n",
       "...      ...                                                ...    ...\n",
       "3995    1995                        A creative comedy/thriller.      1\n",
       "3996    1996  Explores paranoia and insecurity in America's ...      1\n",
       "3997    1997                            Good for power grating.      1\n",
       "3998    1998  McGrath's variation on the novel crafts moving...      1\n",
       "3999    1999  Haneke's creepy explorations are rewarded with...      1\n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([train_2022,data_augmentation_chatGPT], ignore_index=True)\n",
    "# merged_data = merged_data.sample(n=100, random_state=42)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0939f95-727f-4b3c-9fea-1860eb60f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24324165284633636\n",
      "Epoch 2, Loss: 0.13849379122257233\n",
      "Epoch 3, Loss: 0.007841243408620358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       416\n",
      "           1       0.78      0.93      0.85       384\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.85      0.84      0.84       800\n",
      "weighted avg       0.85      0.84      0.84       800\n",
      "\n",
      "CPU times: total: 3h 15min 53s\n",
      "Wall time: 1h 44min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 確認CUDA是否可用\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "# 載入預訓練的 DistilBERT tokenizer 和模型，並將它們移動到CUDA設備上\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# 讀取數據\n",
    "train_data = merged_data.copy()\n",
    "\n",
    "# 使用 tokenizer 將文本轉換為 token IDs 和注意力遮罩\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text, \n",
    "        max_length=128, \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_data['encoding'] = train_data['TEXT'].apply(tokenize_text)\n",
    "train_data['input_ids'] = train_data['encoding'].apply(lambda x: x['input_ids'].squeeze(0))\n",
    "train_data['attention_mask'] = train_data['encoding'].apply(lambda x: x['attention_mask'].squeeze(0))\n",
    "\n",
    "# 將資料拆分為訓練集和測試集\n",
    "train_inputs, test_inputs, train_masks, test_masks, train_labels, test_labels = train_test_split(\n",
    "    torch.stack(train_data['input_ids'].tolist()),\n",
    "    torch.stack(train_data['attention_mask'].tolist()),\n",
    "    train_data['LABEL'].tolist(), \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 創建 PyTorch DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 定義 optimizer 和損失函數\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 訓練模型\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        inputs, masks, labels = tuple(t.to(device) for t in batch)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# 評估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_inputs, test_masks = test_inputs.to(device), test_masks.to(device)\n",
    "    outputs = model(input_ids=test_inputs, attention_mask=test_masks)\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "# 計算分類報告\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb1c419-984b-43a6-aed3-9516f9ddc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "def export_csv(df,name):\n",
    "  now = datetime.datetime.now().astimezone(pytz.timezone('Asia/Taipei'))\n",
    "  formatted_time = now.strftime('%Y%m%d')\n",
    "  df.to_csv('result/'+ formatted_time + '_' + name + \".csv\", index=False,encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2536c3d5-7d5f-48e2-b6e3-866031b942be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       row_id                                               TEXT  LABEL\n",
      "0           0   good to know if you can t find these elsewhere .      0\n",
      "1           1  love it !  the grill plates come out and pop i...      1\n",
      "2           2  i m convinced this was a poorly executed refur...      0\n",
      "3           3  i would never have complained about that if it...      0\n",
      "4           4  the photo shows the same whole ,  large candie...      1\n",
      "...       ...                                                ...    ...\n",
      "10995   10995             i didn t quite get it the first time .      0\n",
      "10996   10996  i ve tried installing with and without the oem...      1\n",
      "10997   10997  i was parked at a truck stop in the cincinnati...      0\n",
      "10998   10998  i recently bought this case after seeing some ...      1\n",
      "10999   10999  the keyboard types only % of the time and the ...      0\n",
      "\n",
      "[11000 rows x 3 columns]\n",
      "CPU times: total: 1h 30min 20s\n",
      "Wall time: 31min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 預處理測試數據\n",
    "test_data = pd.read_csv('test_no_answer_2022.csv')\n",
    "result = test_data.copy()\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text, \n",
    "        max_length=128, \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "test_data['encoding'] = test_data['TEXT'].apply(tokenize_text)\n",
    "test_data['input_ids'] = test_data['encoding'].apply(lambda x: x['input_ids'].squeeze(0))\n",
    "test_data['attention_mask'] = test_data['encoding'].apply(lambda x: x['attention_mask'].squeeze(0))\n",
    "\n",
    "# 將處理好的數據轉換為 DataLoader\n",
    "test_inputs = torch.stack(test_data['input_ids'].tolist())\n",
    "test_masks = torch.stack(test_data['attention_mask'].tolist())\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)  # 可以調整batch size\n",
    "\n",
    "# 使用模型進行預測\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, masks = tuple(t.to(device) for t in batch)\n",
    "        outputs = model(input_ids=inputs, attention_mask=masks)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "# 將預測結果附加到 DataFrame 並保存或打印結果\n",
    "result['LABEL'] = predictions\n",
    "print(result[['row_id', 'TEXT', 'LABEL']])\n",
    "\n",
    "# 可選：將預測結果保存到 CSV 文件\n",
    "export_csv(result.drop(columns=['TEXT']),'Distill_BERT_FineTune_SST2_4000_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d899a4-d019-4321-abe2-d92a236a1d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>encoding</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>good to know if you can t find these elsewhere .</td>\n",
       "      <td>{'input_ids': tensor([[ 101, 2204, 2000, 2113,...</td>\n",
       "      <td>tensor([ 101, 2204, 2000, 2113, 2065, 2017, 20...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>love it !  the grill plates come out and pop i...</td>\n",
       "      <td>{'input_ids': tensor([[  101,  2293,  2009,   ...</td>\n",
       "      <td>tensor([  101,  2293,  2009,   999,  1996, 186...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i m convinced this was a poorly executed refur...</td>\n",
       "      <td>{'input_ids': tensor([[  101,  1045,  1049,  6...</td>\n",
       "      <td>tensor([  101,  1045,  1049,  6427,  2023,  20...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i would never have complained about that if it...</td>\n",
       "      <td>{'input_ids': tensor([[  101,  1045,  2052,  2...</td>\n",
       "      <td>tensor([  101,  1045,  2052,  2196,  2031, 108...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the photo shows the same whole ,  large candie...</td>\n",
       "      <td>{'input_ids': tensor([[  101,  1996,  6302,  3...</td>\n",
       "      <td>tensor([  101,  1996,  6302,  3065,  1996,  21...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>10995</td>\n",
       "      <td>i didn t quite get it the first time .</td>\n",
       "      <td>{'input_ids': tensor([[ 101, 1045, 2134, 1056,...</td>\n",
       "      <td>tensor([ 101, 1045, 2134, 1056, 3243, 2131, 20...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>10996</td>\n",
       "      <td>i ve tried installing with and without the oem...</td>\n",
       "      <td>{'input_ids': tensor([[  101,  1045,  2310,  2...</td>\n",
       "      <td>tensor([  101,  1045,  2310,  2699, 23658,  20...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>10997</td>\n",
       "      <td>i was parked at a truck stop in the cincinnati...</td>\n",
       "      <td>{'input_ids': tensor([[ 101, 1045, 2001, 9083,...</td>\n",
       "      <td>tensor([ 101, 1045, 2001, 9083, 2012, 1037, 47...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>10998</td>\n",
       "      <td>i recently bought this case after seeing some ...</td>\n",
       "      <td>{'input_ids': tensor([[ 101, 1045, 3728, 4149,...</td>\n",
       "      <td>tensor([ 101, 1045, 3728, 4149, 2023, 2553, 20...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>10999</td>\n",
       "      <td>the keyboard types only % of the time and the ...</td>\n",
       "      <td>{'input_ids': tensor([[ 101, 1996, 9019, 4127,...</td>\n",
       "      <td>tensor([ 101, 1996, 9019, 4127, 2069, 1003, 19...</td>\n",
       "      <td>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id                                               TEXT  \\\n",
       "0           0   good to know if you can t find these elsewhere .   \n",
       "1           1  love it !  the grill plates come out and pop i...   \n",
       "2           2  i m convinced this was a poorly executed refur...   \n",
       "3           3  i would never have complained about that if it...   \n",
       "4           4  the photo shows the same whole ,  large candie...   \n",
       "...       ...                                                ...   \n",
       "10995   10995             i didn t quite get it the first time .   \n",
       "10996   10996  i ve tried installing with and without the oem...   \n",
       "10997   10997  i was parked at a truck stop in the cincinnati...   \n",
       "10998   10998  i recently bought this case after seeing some ...   \n",
       "10999   10999  the keyboard types only % of the time and the ...   \n",
       "\n",
       "                                                encoding  \\\n",
       "0      {'input_ids': tensor([[ 101, 2204, 2000, 2113,...   \n",
       "1      {'input_ids': tensor([[  101,  2293,  2009,   ...   \n",
       "2      {'input_ids': tensor([[  101,  1045,  1049,  6...   \n",
       "3      {'input_ids': tensor([[  101,  1045,  2052,  2...   \n",
       "4      {'input_ids': tensor([[  101,  1996,  6302,  3...   \n",
       "...                                                  ...   \n",
       "10995  {'input_ids': tensor([[ 101, 1045, 2134, 1056,...   \n",
       "10996  {'input_ids': tensor([[  101,  1045,  2310,  2...   \n",
       "10997  {'input_ids': tensor([[ 101, 1045, 2001, 9083,...   \n",
       "10998  {'input_ids': tensor([[ 101, 1045, 3728, 4149,...   \n",
       "10999  {'input_ids': tensor([[ 101, 1996, 9019, 4127,...   \n",
       "\n",
       "                                               input_ids  \\\n",
       "0      tensor([ 101, 2204, 2000, 2113, 2065, 2017, 20...   \n",
       "1      tensor([  101,  2293,  2009,   999,  1996, 186...   \n",
       "2      tensor([  101,  1045,  1049,  6427,  2023,  20...   \n",
       "3      tensor([  101,  1045,  2052,  2196,  2031, 108...   \n",
       "4      tensor([  101,  1996,  6302,  3065,  1996,  21...   \n",
       "...                                                  ...   \n",
       "10995  tensor([ 101, 1045, 2134, 1056, 3243, 2131, 20...   \n",
       "10996  tensor([  101,  1045,  2310,  2699, 23658,  20...   \n",
       "10997  tensor([ 101, 1045, 2001, 9083, 2012, 1037, 47...   \n",
       "10998  tensor([ 101, 1045, 3728, 4149, 2023, 2553, 20...   \n",
       "10999  tensor([ 101, 1996, 9019, 4127, 2069, 1003, 19...   \n",
       "\n",
       "                                          attention_mask  predicted_labels  \n",
       "0      tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 1  \n",
       "1      tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 1  \n",
       "2      tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 0  \n",
       "3      tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 1  \n",
       "4      tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 1  \n",
       "...                                                  ...               ...  \n",
       "10995  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,...                 0  \n",
       "10996  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 0  \n",
       "10997  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 0  \n",
       "10998  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 1  \n",
       "10999  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                 0  \n",
       "\n",
       "[11000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = pd.read_csv('test_predictions.csv')\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd5bf9-621b-47df-ac42-f5675f4a7a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa98c94-6f59-4d6b-80b7-281de57c0234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2ae92-0a11-4e02-8409-920d97b7cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b3860-ec48-445b-9ae9-4aa67a829e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664ebf8-90b6-48cf-99a5-98584302afff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4899c296-eb8d-4e6c-afc0-7d8558603bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
